**F5 Interview Questions and Answers for 15+ Years Experienced Engineer**

backendserver---intface---f5---extface---internet

### **Basic to Advanced Questions**  

1. **How does F5 handle SSL offloading, and when would you use SSL bridging instead?**  
   - **SSL Offloading**: The F5 terminates SSL at the VIP, decrypts traffic, and sends it to backend servers unencrypted. This reduces the backend server's CPU load.  
   - **SSL Bridging**: The F5 decrypts the traffic, inspects/modifies it, then re-encrypts before forwarding it to the backend servers. This is used when end-to-end encryption is required.  

2. **What happens if all pool members in an F5 LTM go down? How can you ensure high availability?**  
   - If **no pool members are available**, the VIP will stop serving traffic (default behavior).  
   - Solutions:  
     - **Use a fallback host** (send traffic to a default page).  
     - **Configure priority groups** (so backup servers can take over).  
     - **Enable monitor failover** (so traffic is redirected elsewhere).  
     - **Use GTM** to redirect traffic to a different data center.  

3. **Explain the difference between SNAT and automap in F5. When would you use each?**  
   - **SNAT (Static NAT)**: You manually define the source IP for outgoing connections. Used when backend servers need a fixed public IP for outbound traffic.  
   - **SNAT Automap**: F5 automatically translates the source IP to the self-IP of the F5 interface handling the connection. Used when backend servers don’t have a default route back through F5.  

4. **How does F5 handle session persistence when a client switches between different ISPs?**  
   - Standard **source IP persistence** may break since the client’s IP changes.  
   - Use **cookie persistence** or **SSL session ID persistence** to maintain session continuity.  

5. **What’s the impact of enabling OneConnect on a virtual server?**  
   - **OneConnect** allows multiple client requests to reuse a single server-side connection, reducing connection overhead and improving performance.  
   - If misconfigured, it can cause session mix-ups in applications that rely on client IP persistence.  

---

### **Tricky & Scenario-Based Questions**  

6. **You see an "empty response" issue for HTTPS traffic on an F5 VIP. What troubleshooting steps would you take?**  
   - **Check the SSL profile** on the virtual server. Ensure the correct certificate and key are attached.  
   - **Verify backend SSL settings** (if re-encryption is enabled, the backend must support it).  
   - **Capture TCP dumps** (`tcpdump -ni 0.0:nnn port 443`) to analyze traffic flow.  
   - **Look at logs (`/var/log/ltm` & `/var/log/tmm`)** for SSL handshake errors.  
   - **Check cipher suites**: If mismatched, the connection may fail.  

7. **How would you configure F5 to handle WebSockets while ensuring persistence?**  
   - Use **FastL4 or Performance Layer 4 virtual server** to avoid interfering with WebSocket handshakes.  
   - If L7 inspection is required, use an **HTTP profile with "websockets enabled"**.  
   - For persistence, use **source IP persistence** or **cookie-based persistence**.  

8. **A client reports intermittent connection drops via F5, but backend servers are healthy. What could be causing this?**  
   - **Connection timeouts**: Increase the idle timeout in TCP or HTTP profiles.  
   - **SNAT exhaustion**: If many clients are NATed to a single IP, it may run out of ephemeral ports.  
   - **TCP resets**: Check `tcpdump` and logs for reset reasons.  
   - **Health monitor flapping**: If F5 incorrectly marks servers up/down, it may drop connections.  

9. **How can you mitigate DDoS attacks at the F5 level without an external security appliance?**  
   - Enable **DoS protection profiles** to block excessive requests.  
   - Use **iRules** to filter out bad requests based on User-Agent, source IP, or request patterns.  
   - Rate-limit connections using **connection limits** on VIPs or pools.  
   - Configure **AFM (if licensed)** to block volumetric attacks.  
   - Enable **TCP SYN Cookies** to prevent SYN flood attacks.  

10. **If an iRule and an LTM policy both apply to a request, which one takes precedence?**  
   - **LTM Policies execute first.** If an iRule is attached, it will execute afterward unless explicitly overridden by the policy.  
   - Best practice: Use **LTM policies** for simple traffic steering and **iRules** for advanced logic.  

---

### **Why Do We Need AFM (Advanced Firewall Manager)?**
- **Protects Against Network-Based Attacks**: AFM defends against DDoS, SYN floods, and brute-force attacks.
- **Deep Packet Inspection (DPI)**: Provides advanced filtering beyond traditional firewalls.
- **Layer 3-4 Firewalling**: Implements network-layer security controls with high-performance enforcement.
- **Rate Limiting & Traffic Policing**: Helps mitigate bot traffic and abuse attempts.
- **Seamless Integration with LTM & ASM**: Works with other F5 modules for comprehensive security.

---

### **F5 OS Upgrade Automation Script**

#### **Standalone Upgrade Script**
```bash
tmsh save sys ucs /var/local/ucs/backup.ucs
scp BIGIP-XX.iso root@<F5-IP>:/var/tmp/
tmsh install sys software image BIGIP-XX.iso volume HD1.X
tmsh reboot volume HD1.X
tmsh show sys version
```

#### **HA Upgrade Script**
```bash
# Step 1: Failover Active to Standby
tmsh run sys failover standby

# Step 2: Upgrade Standby
scp BIGIP-XX.iso root@<Standby-F5-IP>:/var/tmp/
tmsh install sys software image BIGIP-XX.iso volume HD1.X
tmsh reboot volume HD1.X

# Step 3: Verify and Failback
sleep 300  # Wait for reboot
tmsh run sys failover active

# Step 4: Upgrade Former Active Unit
scp BIGIP-XX.iso root@<Active-F5-IP>:/var/tmp/
tmsh install sys software image BIGIP-XX.iso volume HD1.X
tmsh reboot volume HD1.X
```

### **Upgrade Notes**
- Always take a **UCS backup** before upgrading.
- Verify active/standby state before failover.
- Ensure enough disk space on the target partition.
- Monitor upgrade logs (`tail -f /var/log/ltm`).
- After upgrade, validate application functionality before switching traffic back.


LTM Load Balancing Connection Related Questions and Answers

1. How does LTM determine which pool member to send traffic to when using round-robin load balancing in the presence of server-side session persistence (e.g., cookie-based persistence)?
Answer: When using round-robin load balancing with session persistence enabled (such as cookie-based persistence), LTM first checks if there is an existing persistent session. If a session is found, LTM directs traffic to the pool member that the session is bound to, regardless of the round-robin order. If no session exists or the session expires, LTM will start the round-robin algorithm and send the new request to the next pool member in sequence.

2. In an LTM configuration, how can you troubleshoot issues when one pool member is consistently underutilized while others are overloaded, even though the load balancing method is set to Least Connections?
Answer: When Least Connections is configured but a pool member is underutilized while others are overloaded, consider the following troubleshooting steps:
- Check persistence settings: If session persistence is configured (such as cookie or source address persistence), it could be causing traffic to consistently hit certain members, skewing the load.
- Examine the health monitor configuration: Ensure the health monitors for the underutilized pool member are correctly configured and that the member is not intermittently failing health checks.
- Verify connection limits: Check for any connection limits on the underutilized server that could be preventing it from handling more connections.
- Review session sticky settings: If sticky sessions are in play, they might be affecting the balancing. Make sure persistence is correctly configured to avoid sticking connections to only certain servers.

3. Explain the process of connection multiplexing in F5 LTM and how it optimizes the usage of server resources. How can connection multiplexing be disabled if required?
Answer: Connection multiplexing allows LTM to reuse existing server-side connections for multiple client requests, reducing the overhead of creating new connections for every request. This improves server resource usage, especially in high-traffic environments. The mechanism works by keeping a persistent connection open to a server and using it to handle multiple requests from different clients.
To disable connection multiplexing, you can modify the connection multiplexing settings in the LTM configuration by adjusting the 'Keep-Alive' and 'Multiplex' parameters. For example, setting the connection reuse settings to 'disabled' on a virtual server will prevent multiplexing.

4. When using LTM’s Adaptive Load Balancing, how does LTM calculate the 'Effective Weight' of a pool member, and how do these calculations change when a member is in a disabled state or is marked as 'forced offline'?
Answer: In Adaptive Load Balancing (ALB), LTM calculates the 'Effective Weight' of a pool member based on factors such as:
- Health status: A member that is healthy will have a higher weight.
- Performance: If a pool member is performing poorly, it will have a reduced weight.
- Connection count: A member with fewer active connections may be assigned a higher weight to handle more traffic.
When a member is in a 'disabled' state, its weight becomes 0, and it will not be used for traffic distribution. If a member is 'forced offline', LTM stops sending traffic to it, and the 'Effective Weight' is also 0, effectively removing it from the load balancing pool.

5. How does LTM handle TCP connections when performing SSL offloading and connection reuse? Explain the sequence of events from the moment a client initiates a connection until the server sends back a response.
Answer: When LTM performs SSL offloading, the sequence of events typically follows this process:
1. Client initiates a TCP connection: The client connects to the LTM, which is listening on the SSL port.
2. SSL handshake: LTM performs an SSL handshake with the client, establishing an encrypted connection.
3. SSL offload: Once the SSL handshake is complete, LTM decrypts the client request.
4. Traffic forwarding: LTM forwards the decrypted traffic to the appropriate backend pool member over an unencrypted TCP connection (if SSL offloading is fully implemented).
5. Server processes request: The pool member processes the request and generates a response.
6. Response is encrypted: The pool member's response is sent back to LTM, which re-encrypts it and forwards it to the client.
7. Connection reuse: If connection reuse is enabled (such as connection multiplexing), LTM may keep the TCP connection to the backend server open for future requests, reducing connection setup overhead.

6. What are the potential pitfalls of using 'Least Connections' as the load balancing method in environments where long-lived connections are common? How can this affect the overall system’s scalability?
Answer: In environments with long-lived connections, the 'Least Connections' load balancing method can cause issues because it tends to direct traffic to servers with fewer active connections. If a server has long-lived connections, it may not appear to have enough 'active' connections, causing it to be underutilized, even though it is still handling a significant load.
This can affect scalability because:
- Some servers may be overwhelmed while others are underutilized.
- It can lead to inefficient resource usage, especially if connections are idle but still counted as active.
To mitigate this, 'Least Connections (Member)' or 'Least Connections (Global)' might be better choices, or a different load balancing method (such as 'Least Sessions') could be used to account for long-lived connections.

7. How does LTM handle connection persistence in a high-availability pair, and what configuration changes would be needed to ensure connection persistence is maintained if the active unit fails?
Answer: In an LTM high-availability pair, connection persistence (e.g., session cookies, source address affinity) is maintained by using sync settings that replicate session information across both devices. When the active unit fails, the standby unit takes over, but it must have up-to-date session information to ensure continuity.
To ensure connection persistence is maintained during a failover:
- Configure Sync-Failover: This ensures session persistence information, as well as other configurations, is synchronized between the active and standby units.
- Check the 'Persistence' settings: Ensure persistence modes (like cookie-based persistence) are supported by both devices.
- Ensure session tables are synchronized: Make sure the session table sync is enabled to transfer session information across devices.

8. When using LTM to load balance HTTP traffic with a web application firewall (WAF) deployed, how does LTM interact with the WAF to ensure secure and efficient traffic distribution?
Answer: When using LTM in conjunction with a WAF, LTM typically performs the following steps:
1. Traffic redirection to WAF: LTM forwards HTTP traffic to the WAF for inspection before it reaches the backend servers.
2. WAF inspection: The WAF inspects the traffic for security issues (e.g., SQL injection, cross-site scripting) and either allows or denies traffic based on predefined rules.
3. Traffic forwarding: If the traffic is deemed safe, the WAF sends it back to LTM, which then routes it to the appropriate pool member.
In this setup, LTM ensures:
- Efficient traffic distribution: LTM continues to load balance across servers, but it first ensures that traffic is passed through the WAF.
- Session persistence: LTM still handles session persistence, ensuring traffic from a client is directed to the same server after being inspected by the WAF.
For optimal performance and security, configurations like SSL offloading at LTM and Deep Packet Inspection at the WAF are usually employed.

Sticky sessions (also known as persistence) and cookie-based load balancing are important concepts in load balancing that ensure a user's requests are directed to the same server during their session. Let's dive into these concepts in more detail.
1. Sticky Sessions / Persistence

Sticky sessions, or session persistence, ensure that once a user is directed to a particular server, their subsequent requests are always directed to the same server for the duration of their session. This is important for applications that maintain session data (like user login state or shopping cart contents) on the server rather than the client.
How It Works:
 
    Session Persistence Mechanism: LTM (Local Traffic Manager) uses various methods to achieve persistence. These methods ensure that all requests from a particular client go to the same backend server.
        Source IP Persistence: Based on the client's IP address, LTM will always send traffic from the same source IP to the same pool member.
        Cookie Persistence: LTM inserts a cookie in the client's response, and the client sends that cookie back with subsequent requests to identify the session and route it to the same server.

2. Cookie-Based Load Balancing

In cookie-based persistence, LTM uses cookies to track client sessions. It can either insert a session cookie or rely on an existing cookie (like an application cookie). This is especially useful for web applications where clients may have varying IP addresses or network conditions, making source IP persistence unreliable.
How Cookie-Based Persistence Works:

    Server Response: When a client first makes a request, LTM routes the request to a pool member. LTM then inserts a special cookie into the response header.
    Cookie Value: The cookie contains information such as the server to which the request was routed. The cookie might look like this:

    BIGipServer~app_pool=server1

    Subsequent Requests: The client sends the cookie with each subsequent request, and LTM reads the cookie value to determine which server the request should go to.
    Cookie Expiration: Cookies can have an expiration time. If the cookie expires, the session will be re-routed to the least-loaded server based on the load-balancing method (like round-robin or least connections).

Example:

Let’s assume you have a web application with multiple backend servers. The user, Bob, logs in to your website and makes a request to server1. LTM inserts a cookie in Bob’s browser like:

BIGipServer~web_app_pool=server1

Bob logs out and then logs in again. LTM checks the cookie and routes Bob's subsequent requests to server1, even if other servers are available. The cookie ensures Bob's session remains on server1.
Advantages of Cookie-Based Persistence:

    Flexibility: Works well when the source IP address changes (e.g., users behind load balancers or mobile networks).
    Scalability: Unlike source IP persistence, cookie-based persistence doesn't require the server to track the client’s IP address, which is ideal in cloud environments where clients' IP addresses are often dynamic.

3. Use Cases and Configuration Examples
Example 1: E-Commerce Website

In an e-commerce website, a user may have a shopping cart that is stored on a particular web server. It is important to ensure that the user interacts with the same server during their entire shopping session. For this scenario, cookie-based persistence is commonly used:

    A cookie is set by LTM on the user’s first request, linking them to a specific backend server.
    All subsequent requests from the user, even if they come from different IP addresses (e.g., when using mobile data), will include the same cookie, ensuring the user is routed to the same server.

Example 2: Online Banking Application

An online banking application may have more strict requirements for session persistence, as user sessions involve sensitive data. Source IP persistence could be used here, as the user's IP is less likely to change during their session:

    The first request is routed to a pool member based on the user’s source IP.
    All subsequent requests from the same IP are sent to the same backend server, ensuring that the session remains secure and stateful.

4. When to Use Persistence:

    Session Data: When the application stores session data locally on a particular server (e.g., login state, shopping cart contents).
    Consistency: When you need to ensure consistency in handling a session, particularly for applications where switching servers mid-session can break the user experience (e.g., online banking).
    Limited Server Resources: When you have a small number of backend servers and need to distribute sessions evenly without overwhelming any server.

5. Disadvantages of Persistence:

    Scalability Issues: If many clients are directed to the same server based on session persistence, the server might become overloaded. If not managed properly, this can reduce the overall scalability of the application.
    Session Stickiness: When a user switches devices or their session cookie expires, they may be routed to a different server, potentially causing a loss of session data unless proper state management is in place.
    Session Failover: If a server goes down, users who were relying on session persistence may be disconnected or experience issues if the session data isn't replicated to other servers.

6. Load Balancing Algorithms with Persistence

Persistence works with various load balancing algorithms to distribute traffic intelligently:

    Round-robin: The default method of distributing traffic equally across all pool members.
    Least Connections: Sends traffic to the pool member with the least number of active connections, but persistence ensures that the same client continues to be directed to the same server.
    Weighted Methods: Some pool members may be more powerful than others. Weighted round-robin or least-connections methods can take the server’s weight into account while still maintaining session persistence.

7. Configuring Cookie-Based Persistence on F5 LTM:

Here’s a simplified configuration for cookie-based persistence on an F5 LTM:

    Create a Persistence Profile:
        Navigate to Local Traffic > Profiles > Persistence.
        Create a Cookie Persistence Profile.
        Set options like:
            Cookie Name: Name of the cookie.
            Timeout: Duration the cookie will persist.
            TTL: Time-to-live for the cookie.

    Apply the Profile to a Virtual Server:
        Go to Local Traffic > iRules or Virtual Servers.
        Apply the newly created Cookie Persistence Profile to your virtual server.

    Behavior:
        When a client first makes a request, LTM will insert the cookie into the response.
        For subsequent requests, LTM checks the cookie and sends traffic to the same server.

Conclusion

Sticky sessions and cookie-based load balancing are crucial for managing sessions in distributed web applications. By ensuring that users are consistently routed to the same server for the duration of their session, these techniques maintain session integrity, particularly for applications with user-specific data. However, careful consideration should be given to the potential scalability challenges and how persistence is configured across your infrastructure.

content_persistence = """
Source IP Persistence vs Cookie Persistence

1. **Source IP Persistence**
Source IP Persistence (also known as IP Affinity) uses the IP address of the client to ensure that the same backend server handles all requests from the same client.

Information in Source IP Persistence:
- **Client’s Source IP Address**: The IP address of the client making the request (e.g., the user's device or browser).
- **Mapping to Pool Member**: A mapping table is maintained by the load balancer, associating source IPs with pool members (backend servers).

How It Works:
1. The client sends a request to the load balancer.
2. The load balancer checks the source IP address of the request.
3. If it’s the first request from this IP (or the session has expired), the load balancer chooses a backend server based on the load balancing method.
4. For any subsequent requests from the same IP, the load balancer routes them to the same backend server.

Example:
- Client A (IP 192.168.1.10) makes a request.
- The load balancer assigns Client A to Server 1.
- Subsequent requests from Client A (IP 192.168.1.10) go to **Server 1**.

**Pros**:
- Simple to configure.
- Works well with static IPs (e.g., internal fixed IPs).
- Doesn’t require cookies or application changes.

**Cons**:
- **Dynamic IPs**: Issues arise with clients using dynamic IP addresses (e.g., mobile networks).
- **NAT Issues**: Clients behind NAT may cause multiple clients to share the same public IP.

2. **Cookie Persistence**
Cookie Persistence involves inserting a special cookie into the client’s response header to maintain session persistence.

Information in Cookie Persistence:
- **Cookie Name**: The name of the cookie used by the load balancer to track session persistence (e.g., BIGipServer~web_app_pool).
- **Cookie Value**: Contains session information or server identity (e.g., `server1`), used to route subsequent requests to the same backend server.
- **Expiration Time (TTL)**: Defines how long the cookie is valid.
- **Client ID or Session ID (optional)**: Some applications may include additional session information within the cookie.

How It Works:
1. The client makes a request to the load balancer.
2. The load balancer routes the request to a backend server and inserts a cookie in the response header:
   - `Set-Cookie: BIGipServer~web_app_pool=server1`
3. The client sends the cookie back in subsequent requests.
4. The load balancer uses the cookie value to route requests to the same backend server (e.g., `server1`).

Example:
- Client B visits a website.
- The load balancer routes Client B to Server 2 and inserts a cookie:
   - `Set-Cookie: BIGipServer~web_app_pool=server2`
- Subsequent requests from Client B will be routed to **Server 2**.

**Pros**:
- Works well in dynamic IP environments (e.g., mobile networks).
- Doesn’t require the client’s IP address to maintain persistence.
- Scalable as it doesn’t rely on IP addresses.

**Cons**:
- **Cookie Overhead**: The client must send the cookie with every request, adding overhead.
- **Session Expiration**: If the cookie expires, the user may be redirected to another server.
- **Security Risks**: Improperly secured cookies can be hijacked, leading to session fixation or man-in-the-middle attacks.

**Key Differences Between Source IP and Cookie Persistence**:

| Feature                        | **Source IP Persistence**                              | **Cookie Persistence**                                 |
|---------------------------------|--------------------------------------------------------|--------------------------------------------------------|
| **Tracking Mechanism**          | Based on the client's source IP address                | Based on a session cookie inserted by the load balancer|
| **Session Identification**      | Identified by client IP address                        | Identified by a cookie sent by the client              |
| **Client-side Impact**          | No need for client to store anything                   | Client stores a cookie in the browser                  |
| **Use Case**                    | Works best when clients have static IP addresses       | Suitable for environments with dynamic IPs or NAT      |
| **Scalability**                 | Limited by NAT and shared IP issues                    | Scalable, as it doesn't depend on IP addresses         |
| **Failure Scenario**            | Client IP change (e.g., roaming) can break persistence | Cookie expiration or deletion can break persistence    |

Conclusion:
- **Source IP Persistence** is simpler to configure and works best in static IP environments.
- **Cookie Persistence** is more flexible and scalable, especially in environments with dynamic IPs or NAT. It works well when source IP persistence is unreliable or when users need to access the application from different devices.
"""

F5-Ext 10.10.10.10 ---pa/router--external(10.10.10.10 nat to) 1.1.1.1


1. Deployment Modes
a) One-Arm Mode (SNAT Mode)

    F5 has only one network interface (VLAN) connected to the network.
    Uses SNAT (Source Network Address Translation) to ensure responses pass through F5.
    Ideal for simple deployments or when backend servers don’t have F5 as their default gateway.

Traffic Flow

    Client → Virtual Server (VS) (F5 intercepts request).
    F5 changes source IP to SNAT IP.
    Request forwarded to backend.
    Backend responds to SNAT IP, ensuring return traffic flows via F5.
    F5 forwards response to client.

Use Cases

✅ Cloud and virtual environments.
✅ When backend servers don’t change their default gateway.
✅ Easy to implement without major network changes.

b) Two-Arm Mode (Routed Mode)

    F5 is connected to two VLANs:
        External VLAN (Client-facing)
        Internal VLAN (Backend-facing)
    Backend servers have F5 as their default gateway (no SNAT required).

Traffic Flow

    Client sends request to F5 VIP.
    F5 forwards request to backend without modifying source IP.
    Backend routes response through F5.
    F5 forwards response back to client.

Use Cases

✅ Full visibility of client IP (no SNAT needed).
✅ More control over traffic routing.
✅ Works well in data centers and large environments.
2. High Availability (HA) Deployment

    F5 devices can be clustered in Active-Standby or Active-Active mode.
    Ensures failover in case of device failure.

HA Setup

    Two or more F5 devices.
    Config Sync between F5 devices.
    Failover mechanism (via network heartbeat and floating IPs).

Use Cases

✅ Mission-critical applications requiring zero downtime.
✅ Enterprise deployments with redundancy needs.
3. Common F5 Deployment Scenarios
a) Load Balancer (LTM - Local Traffic Manager)

    Distributes traffic across multiple backend servers.
    Provides health checks, persistence, SSL offloading, and traffic optimization.

Example

    VIP (Virtual Server): 192.168.1.100 (F5 listens here).
    Backend Servers: 192.168.2.10, 192.168.2.11, 192.168.2.12.
    Traffic is balanced across backend servers.

b) Global Load Balancing (GTM - Global Traffic Manager---F5-DNS)

    Distributes traffic across multiple data centers---MIA-LTM and CUL-LTM.
    Uses DNS-based load balancing to route users to the nearest or healthiest location.

Use Case

✅ Multi-region applications needing disaster recovery.
✅ Geolocation-based traffic routing.
c) SSL Offloading

    F5 handles SSL/TLS decryption to reduce load on backend servers.
    Backend servers receive decrypted HTTP traffic.

Use Case

✅ Performance optimization.
✅ Easier SSL certificate management.
d) Web Application Firewall (WAF - ASM Module)

    Protects against OWASP Top 10 attacks.
    Used for web security & API protection.

Use Case

✅ E-commerce and online banking for protection against web attacks.
✅ Defense against SQL Injection, XSS, and DDoS.
